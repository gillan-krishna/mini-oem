{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import rasterio\n",
    "import cv2\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import src\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OEM_DATA_DIR = Path('data/processing/OpenEarthMap_Mini')\n",
    "TRAIN_LIST = OEM_DATA_DIR.joinpath('train.txt')\n",
    "VAL_LIST = OEM_DATA_DIR.joinpath('val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "N_CLASSES = 9\n",
    "LR = 3e-4\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [f for f in Path(OEM_DATA_DIR).rglob(\"*.tif\") if \"/images/\" in str(f)]\n",
    "train_fns = [str(f) for f in fns if f.name in np.loadtxt(TRAIN_LIST, dtype=str)]\n",
    "val_fns = [str(f) for f in fns if f.name in np.loadtxt(VAL_LIST, dtype=str)]\n",
    "\n",
    "print(\"Total samples      :\", len(fns))\n",
    "print(\"Training samples   :\", len(train_fns))\n",
    "print(\"Validation samples :\", len(val_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augm = torchvision.transforms.Compose(\n",
    "    [\n",
    "        src.transforms.Rotate(),\n",
    "        src.transforms.Crop(IMG_SIZE),\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_augm = torchvision.transforms.Compose(\n",
    "    [\n",
    "        src.transforms.Resize(IMG_SIZE),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = src.dataset.OpenEarthMapDataset(\n",
    "    train_fns,\n",
    "    n_classes=N_CLASSES,\n",
    "    augm=train_augm,\n",
    ")\n",
    "\n",
    "val_data = src.dataset.OpenEarthMapDataset(\n",
    "    val_fns,\n",
    "    n_classes=N_CLASSES,\n",
    "    augm=val_augm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(5*1.5, 2*1.5))\n",
    "fig.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.01, wspace=0.01)\n",
    "\n",
    "IDX = 1\n",
    "for i in range(5):\n",
    "    img, msk, fn = train_data[IDX]\n",
    "\n",
    "    img = np.moveaxis(img.numpy(), 0, -1)\n",
    "    msk = src.utils.make_rgb(np.argmax(msk.numpy(), axis=0))\n",
    "\n",
    "    axs[0, i].imshow(img)\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(msk)\n",
    "    axs[1, i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=10,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=10,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = src.networks.UNet(in_channels=3, n_classes=N_CLASSES)\n",
    "network = src.networks.UnetPlusPlus(encoder_name='resnet18', encoder_weights='imagenet', in_channels=3, classes=N_CLASSES, activation='softmax')\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=LR)\n",
    "# criterion = oem.losses.JaccardLoss()\n",
    "# criterion = src.losses.FocalLoss()\n",
    "criterion = src.custom_loss.BalancedTverskyFocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_run = False\n",
    "import neptune\n",
    "if log_run:\n",
    "    run = neptune.init_run(\n",
    "        project='gillan-k/mini-oem',\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyYWRiZGVlNC04NjA2LTRlMmYtODE4OS0zYWQ4NjFhYTEyMDIifQ==\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   3%|â–Ž         | 5/165 [02:12<1:10:28, 26.43s/it, Loss=7.44, fscore=0.0966]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mrunners\u001b[38;5;241m.\u001b[39mtrain_epoch(\n\u001b[1;32m      8\u001b[0m         model\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[1;32m      9\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     10\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     11\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtrain_data_loader,\n\u001b[1;32m     12\u001b[0m         device\u001b[38;5;241m=\u001b[39mDEVICE,\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     15\u001b[0m     valid_logs \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mrunners\u001b[38;5;241m.\u001b[39mvalid_epoch(\n\u001b[1;32m     16\u001b[0m         model\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[1;32m     17\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     18\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mval_data_loader,\n\u001b[1;32m     19\u001b[0m         device\u001b[38;5;241m=\u001b[39mDEVICE,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m log_run:\n",
      "File \u001b[0;32m~/mini-oem/src/runners.py:86\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m     84\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     85\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m---> 86\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     89\u001b[0m total_loss_meter\u001b[38;5;241m.\u001b[39mupdate(total_loss\u001b[38;5;241m.\u001b[39mitem(), n\u001b[38;5;241m=\u001b[39mn)\n",
      "File \u001b[0;32m~/miniconda3/envs/lulc/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/lulc/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "max_score = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch: {epoch + 1}\")\n",
    "\n",
    "    train_logs = src.runners.train_epoch(\n",
    "        model=network,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        dataloader=train_data_loader,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    valid_logs = src.runners.valid_epoch(\n",
    "        model=network,\n",
    "        criterion=criterion,\n",
    "        dataloader=val_data_loader,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    if log_run:\n",
    "        run['train/loss'] = train_logs['Loss']\n",
    "        # run['train/iou'] = train_logs['IOU']\n",
    "        run['train/fscore'] = train_logs['fscore']\n",
    "        run['val/loss'] = train_logs['Loss']\n",
    "        run['val/fscore'] = train_logs['fscore']\n",
    "    \n",
    "    epoch_score = valid_logs[\"Score\"]\n",
    "    if max_score < epoch_score:\n",
    "        max_score = epoch_score\n",
    "        src.utils.save_model(\n",
    "            model=network,\n",
    "            epoch=epoch,\n",
    "            best_score=max_score,\n",
    "            model_name=\"model.pth\",\n",
    "            output_dir=OUTPUT_DIR,\n",
    "        )\n",
    "\n",
    "print(\"Elapsed time: {:.3f} min\".format((time.time() - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_run:\n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_LIST = os.path.join(OEM_DATA_DIR, \"test.txt\")\n",
    "PREDS_DIR = \"predictions\"\n",
    "os.makedirs(PREDS_DIR, exist_ok=True)\n",
    "\n",
    "img_paths = [f for f in Path(OEM_DATA_DIR).rglob(\"*.tif\") if \"/images/\" in str(f)]\n",
    "test_fns = [str(f) for f in img_paths if f.name in np.loadtxt(TEST_LIST, dtype=str)]\n",
    "\n",
    "print(\"Total samples   :\", len(img_paths))\n",
    "print(\"Testing samples :\", len(test_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = src.dataset.OpenEarthMapDataset(test_fns, n_classes=N_CLASSES, augm=None, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = src.networks.UNet(in_channels=3, n_classes=N_CLASSES)\n",
    "# network = src.utils.load_checkpoint(network, model_name=\"model.pth\", model_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPLOT = 6\n",
    "# idxs = np.argsort(np.random.rand(len(test_fns)))[:NPLOT]\n",
    "\n",
    "# fig, axs = plt.subplots(2, NPLOT, figsize=(NPLOT*1.5, 2*1.5))\n",
    "# fig.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.01, wspace=0.01)\n",
    "\n",
    "# network.eval().to(DEVICE)\n",
    "# for i, idx in enumerate(idxs):\n",
    "#     img, fn = test_data[idx][0], test_data[idx][2]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         prd = network(img.unsqueeze(0).to(DEVICE)).squeeze(0).cpu()\n",
    "#     prd = src.utils.make_rgb(np.argmax(prd.numpy(), axis=0))\n",
    "\n",
    "#     fout = os.path.join(PREDS_DIR, fn.split(\"/\")[-1])\n",
    "#     with rasterio.open(fn, \"r\") as f:\n",
    "#         profile = f.profile\n",
    "#         prd = cv2.resize(\n",
    "#             prd,\n",
    "#             (profile[\"width\"], profile[\"height\"]),\n",
    "#             interpolation=cv2.INTER_NEAREST,\n",
    "#         )\n",
    "#         with rasterio.open(fout, \"w\", **profile) as dst:\n",
    "#             for idx in f.indexes:\n",
    "#                 dst.write(prd[:, :, idx - 1], idx)\n",
    "\n",
    "#     img = np.moveaxis(img.numpy(), 0, -1)\n",
    "#     axs[0, i].imshow(img)\n",
    "#     axs[0, i].set_title(fn.split(\"/\")[-1][:-4])    \n",
    "#     axs[0, i].axis(\"off\")\n",
    "#     axs[1, i].imshow(prd)\n",
    "#     axs[1, i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
